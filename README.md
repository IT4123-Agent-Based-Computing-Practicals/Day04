# Day 04: Sentiment Analysis with NLP üìäüí¨

## üìù Overview

This day covers sentiment analysis techniques using Natural Language Processing (NLP) to analyze and classify text data based on emotional tone. Two different approaches are implemented: custom lexicon-based analysis and API-powered news sentiment analysis.

---

## üìÇ Project Files

### 1Ô∏è‚É£ `Sentiment_Analysis.ipynb` üé≠

**Custom Lexicon-Based Sentiment Analysis**

#### üéØ Purpose

Implements a rule-based sentiment classifier using NLTK for text preprocessing and a custom word dictionary approach.

#### üîß Key Components

- **Text Preprocessing**: Tokenization, stop word removal, and lemmatization
- **Custom Sentiment Lexicon**: Predefined positive and negative word lists
- **Classification Logic**: Word counting algorithm to determine sentiment

#### üìö Libraries Used

- `nltk` - Natural Language Toolkit
- `word_tokenize` - Text tokenization
- `stopwords` - Common word filtering
- `WordNetLemmatizer` - Word normalization

#### üé™ Features

- ‚úÖ Converts text to lowercase
- ‚úÖ Removes stop words
- ‚úÖ Lemmatizes words to base form
- ‚úÖ Counts positive vs negative words
- ‚úÖ Classifies as: positive, negative, or neutral

#### üìä Sample Output

Analyzes customer reviews and general statements to classify sentiment.

---

### 2Ô∏è‚É£ `News_Sentiment_Analysis.ipynb` üì∞

**Real-Time News Sentiment Analysis with API**

#### üéØ Purpose

Fetches live news headlines from NewsAPI and performs sentiment analysis using TextBlob, with visual representation of results.

#### üîß Key Components

- **API Integration**: NewsAPI for fetching US top headlines
- **Sentiment Analysis**: TextBlob polarity scoring
- **Data Visualization**: Horizontal bar chart of sentiment scores

#### üìö Libraries Used

- `requests` - HTTP requests for API calls
- `pandas` - Data manipulation and analysis
- `textblob` - Automated sentiment analysis
- `matplotlib` - Data visualization

#### üé™ Features

- üåê Fetches real-time news articles
- üìä Creates DataFrame with titles and descriptions
- üîç Handles missing data
- üíØ Calculates sentiment polarity (-1 to +1)
- üìà Visualizes top 10 headlines with sentiment scores

#### üìä Visualization

- **X-axis**: Sentiment Score (negative ‚Üê 0 ‚Üí positive)
- **Y-axis**: News Headlines
- **Color**: Sky blue bars for easy reading

---

## üîë Key Concepts Learned

### üß† NLP Preprocessing

- Tokenization
- Stop word removal
- Lemmatization
- Text normalization

### üìê Sentiment Analysis Methods

1. **Lexicon-Based**: Manual word lists with counting logic
2. **Machine Learning-Based**: TextBlob's pre-trained model

### üìä Sentiment Scoring

- **Positive**: > 0 (optimistic, happy, favorable)
- **Neutral**: = 0 (factual, balanced)
- **Negative**: < 0 (pessimistic, critical, unfavorable)

---

## üí° Use Cases

- üõí Customer review analysis
- üì± Social media monitoring
- üì∞ News tone classification
- üíº Brand reputation tracking
- üé¨ Movie/product feedback analysis

---

## üéì Learning Outcomes

‚úÖ Understand text preprocessing pipeline  
‚úÖ Implement custom sentiment classifiers  
‚úÖ Work with external APIs for data collection  
‚úÖ Use pre-trained NLP models (TextBlob)  
‚úÖ Visualize sentiment data effectively  
‚úÖ Compare rule-based vs ML-based approaches

---

## üß© Quick Code Snippets (Easy to Memorize!)

### üîπ Custom Sentiment Analysis Pattern

```python
# 1Ô∏è‚É£ Import & Download
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# 2Ô∏è‚É£ Define Word Lists
positive_words = ["love", "great", "amazing", "happy", "good"]
negative_words = ["worst", "terrible", "bad", "awful", "poor"]

# 3Ô∏è‚É£ Preprocess Function
def preprocess(text):
    text = text.lower()  # lowercase
    words = word_tokenize(text)  # tokenize
    words = [w for w in words if w not in stopwords.words('english')]  # remove stopwords
    lemmatizer = WordNetLemmatizer()
    words = [lemmatizer.lemmatize(w) for w in words]  # lemmatize
    return words

# 4Ô∏è‚É£ Analyze Sentiment
def analyze_sentiment(text):
    words = preprocess(text)
    pos = sum(1 for w in words if w in positive_words)
    neg = sum(1 for w in words if w in negative_words)

    if pos > neg: return "positive"
    elif neg > pos: return "negative"
    else: return "neutral"
```

### üîπ News API Sentiment Pattern

```python
# 1Ô∏è‚É£ Fetch News
import requests
import pandas as pd
from textblob import TextBlob

API_KEY = "your_api_key"
url = f"https://newsapi.org/v2/top-headlines?country=us&apiKey={API_KEY}"
response = requests.get(url)
articles = response.json()['articles']

# 2Ô∏è‚É£ Create DataFrame
df = pd.DataFrame({
    'Title': [a['title'] for a in articles],
    'Description': [a['description'] for a in articles]
})

# 3Ô∏è‚É£ Analyze Sentiment
df['Sentiment'] = df['Title'].apply(lambda x: TextBlob(x).sentiment.polarity)

# 4Ô∏è‚É£ Visualize
import matplotlib.pyplot as plt
plt.barh(df['Title'][:10], df['Sentiment'][:10], color='skyblue')
plt.xlabel("Sentiment Score")
plt.axvline(0, color='black')
plt.show()
```

### üîπ Remember This Pattern! üß†

**Sentiment Analysis Flow:**

1. **Import** ‚Üí Download resources
2. **Preprocess** ‚Üí Clean text (lowercase ‚Üí tokenize ‚Üí remove stopwords ‚Üí lemmatize)
3. **Analyze** ‚Üí Count positive/negative words OR use TextBlob
4. **Classify** ‚Üí positive/negative/neutral
5. **Visualize** ‚Üí (Optional) Show results

**Key Formula:**

```
Sentiment = (Positive Count - Negative Count) / Total Words
```

**TextBlob Shortcut:**

```python
TextBlob("text").sentiment.polarity  # Returns -1 to +1
```
